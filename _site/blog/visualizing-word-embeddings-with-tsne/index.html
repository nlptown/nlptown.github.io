<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Visualizing Word Embeddings with t-SNE &#8211; Yves Peirsman</title>
<meta name="description" content="">
<meta name="keywords" content="NLP, word, embeddings, visualization, t-SNE, GloVe">
<meta name="author" content="Yves Peirsman">
<!-- Twitter Cards -->
	
		<meta name="twitter:card" content="summary">
		<meta name="twitter:image" content=
			
				
						"http://nlp.yvespeirsman.be/images/"
				
			
		>
	
	<meta name="twitter:title" content="Visualizing Word Embeddings with t-SNE">
	<meta name="twitter:description" content="This is the website and blog of Yves Peirsman, Natural Language Processing Consultant.">
	<meta name="twitter:creator" content="@yvespeirsman">


<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Visualizing Word Embeddings with t-SNE">
<meta property="og:description" content="This is the website and blog of Yves Peirsman, Natural Language Processing Consultant.">
<meta property="og:url" content="http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/">
<meta property="og:site_name" content="Yves Peirsman">





<link rel="canonical" href="http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/">
<link href="http://nlp.yvespeirsman.be/feed.xml" type="application/atom+xml" rel="alternate" title="Yves Peirsman Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Webfonts -->
<link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<!-- For all browsers -->
<link rel="stylesheet" href="http://nlp.yvespeirsman.be/assets/css/main.min.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://nlp.yvespeirsman.be/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://nlp.yvespeirsman.be/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://nlp.yvespeirsman.be/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://nlp.yvespeirsman.be/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://nlp.yvespeirsman.be/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-144x144-precomposed.png">

<link rel="stylesheet" href="/css/yves.css">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
	</div> <!--/.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				<li><a href="http://nlp.yvespeirsman.be/" >Home</a></li>
		        
				<li><a href="http://nlp.yvespeirsman.be/blog/" >All Posts</a></li>
		        
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->




<div id="main" role="main">
  <div class="article-author-side">
    
	<a href="http://nlp.yvespeirsman.be"><img src="http://nlp.yvespeirsman.be/images/bio-photo.jpg" class="bio-photo" alt="Yves Peirsman bio photo"></a>

<h3><a href="http://nlp.yvespeirsman.be">Yves Peirsman</a></h3>
<p>Crazy about Natural Language Processing.</p>
<a href="http://twitter.com/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-twitter-square"></i> Twitter</a>


<a href="http://linkedin.com/in/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>










  </div>
  <article>
    <div class="headline-wrap">
      
        <h1><a href="http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/" rel="bookmark" title="Visualizing Word Embeddings with t-SNE">Visualizing Word Embeddings with t-SNE</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <p class="first">When you work with high-dimensional datasets such as the word embeddings produced by <a href="https://code.google.com/p/word2vec/">word2vec</a> or <a href="http://nlp.stanford.edu/projects/glove/">GloVe</a>, it’s important to get a good idea of what the data look like. One option is to create a visualization of the dataset in two dimensions, and simply eyeball the clusters of data points that appear. However, creating a useful low-dimensional visualization is a non-trivial matter. The best solution I’ve found so far is <a href="http://lvdmaaten.github.io/tsne/">t-SNE</a>.</p>

<p>t-SNE was developed by Laurens van der Maaten at the University of Delft. It won Maarten the <a href="https://www.kaggle.com/c/MerckActivity/prospector#186">Merck Visualization Challenge on Kaggle</a>, and has been applied to images, word embeddings, movies, and similar high-dimensional datasets. Maarten’s website contains links to implementations of the technique in a variety of programming languages, in addition to the research papers that go into the gory details of the underlying maths.</p>

<p>I tested out t-SNE by visualizing the 300-dimensional word embeddings produced by GloVe, a deep learning method developed at Stanford University. Word embeddings model the contexts in which words appear, and are often used as a way of measuring the semantic similarity between two words. You can download a large number of example word embeddings directly from the <a href="http://nlp.stanford.edu/projects/glove/">GloVe website</a>. As you’ll see, t-SNE really makes it easy to visualize these 300-dimensional embeddings in two dimensions, and to get a rough idea of their quality.</p>

<p>Let’s go through the process step by step. First we read in the word embeddings and their labels from two text files. The embeddings file should contain one vector per line, with the values for all dimensions separated by tabs. The label file should list the labels for these vectors &mdash; one label per line, in the same order as the vectors in the embeddings file.</p>

<div class="highlight"><pre><code>import numpy as Math
import pylab as Plot

glove_matrix = Math.loadtxt("glove.6B.300d.embeddings.txt");
glove_words = [line.strip() for line in open("glove.6B.300d.labels.txt")]
</code></pre></div>

<p>Obviously, visualizing all 400,000 words in the GloVe download would give a plot that is rather hard to read.  Instead we will focus on the <a href="http://www.rupert.id.au/resources/1000-words.php">2,000 most frequent words in English</a>, according to the <a href="http://www.wordfrequency.info/">American National Corpus</a>. This means we need to select from the GloVe matrix the rows that correspond to these words. We do this by compiling a list of all the row indices for the target words and using that list to assemble our target matrix:</p>

<div class="highlight"><pre><code>target_words = [line.strip().lower() for line in open("4000-most-common-english-words-csv.csv")][:2000]

rows = [glove_words.index(word) for word in target_words if word in glove_words]
target_matrix = glove_matrix[rows,:]
</code></pre></div>

<p>One line of code then puts t-SNE to work. The first argument to the function is the matrix with our word embeddings, the second is the number of dimensions we want to reduce the matrix to:</p>

<div class="highlight"><pre><code>reduced_matrix = tsne(target_matrix, 2);
</code></pre></div>

<p>Finally, we use a scatter plot to visualize the results of the dimensionality reduction:</p>

<div class="highlight"><pre><code>Plot.figure(figsize=(200, 200), dpi=100)
max_x = Math.amax(reduced_matrix, axis=0)[0]
max_y = Math.amax(reduced_matrix, axis=0)[1]
Plot.xlim((-max_x,max_x))
Plot.ylim((-max_y,max_y))

Plot.scatter(reduced_matrix[:, 0], reduced_matrix[:, 1], 20);

for row_id in range(0, len(rows)):
    target_word = glove_words[rows[row_id]]
    x = reduced_matrix[row_id, 0]
    y = reduced_matrix[row_id, 1]
    Plot.annotate(target_word, (x,y))

Plot.savefig("glove_2000.png");
</code></pre></div>

<p>A quick inspection immediately shows the quality of both the GloVe word embeddings and the t-SNE visualization. For example, in the two-dimensional plot all frequent numbers are grouped together. “One” is likely missing because its contextual distribution is so different from the other numbers &mdash; it fulfils more linguistic functions than just counting.</p>

<p><img src="/images/glove-word-embeddings-numbers.png" class="centered" width="300" /><br /></p>

<p>Similarly, there is a separate group of words related to education:</p>

<p><img src="/images/glove-word-embeddings-education.png" class="centered" width="500" /><br /></p>

<p>And here’s another one about crime and punishment:</p>

<p><img src="/images/glove-word-embeddings-crime-and-punishment.png" class="centered" width="500" /><br /></p>

<p>If you take a look at <a href="/images/glove-word-embeddings.png" class="centered">the complete figure</a>, you’ll find similar clusters for body parts, family members, media, food, politics, sports, and many other concepts.</p>

<p>This simple exercise shows t-SNE is a great tool for visualizing word embeddings. It’s easy to use, produces high-quality visualizations, and will certainly contribute to our understanding of high-dimensional datasets.</p>


      <div class="addthis_sharing_toolbox"></div>
      <hr />
      <footer role="contentinfo">
        <div class="article-author-bottom">
          
	<a href="http://nlp.yvespeirsman.be"><img src="http://nlp.yvespeirsman.be/images/bio-photo.jpg" class="bio-photo" alt="Yves Peirsman bio photo"></a>

<h3><a href="http://nlp.yvespeirsman.be">Yves Peirsman</a></h3>
<p>Crazy about Natural Language Processing.</p>
<a href="http://twitter.com/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-twitter-square"></i> Twitter</a>


<a href="http://linkedin.com/in/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>










        </div>
        <p class="byline"><strong>Visualizing Word Embeddings with t-SNE</strong> was published on <time datetime="2015-05-18T18:00:00-04:00">May 18, 2015</time> by <a href="http://nlp.yvespeirsman.be/about" title="About Yves Peirsman">Yves Peirsman</a>.</p>
      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="http://nlp.yvespeirsman.be/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/generating-genre-fiction-with-deep-learning/" title="Generating Genre Fiction with Deep Learning">Generating Genre Fiction with Deep Learning</a></li>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/text-retrieval-6/" title="Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;2: Recommender Systems">Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;2: Recommender Systems</a></li>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/text-retrieval-5/" title="Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;1: Web Search">Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;1: Web Search</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  <footer>
    <span>&copy; 2015 Yves Peirsman. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://nlp.yvespeirsman.be/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://nlp.yvespeirsman.be/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53268217-1', 'auto');
  ga('send', 'pageview');
</script>



  <!-- Go to www.addthis.com/dashboard to customize your tools -->
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-53fb5daa449762bb"></script>
  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yvespeirsman'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



	        

</body>
</html>
