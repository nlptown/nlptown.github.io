<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model &#8211; Yves Peirsman</title>
<meta name="description" content="">
<meta name="keywords" content="NLP, text, retrieval, search, engines, Coursera">
<meta name="author" content="Yves Peirsman">
<!-- Twitter Cards -->
	
		<meta name="twitter:card" content="summary">
		<meta name="twitter:image" content=
			
				
						"http://nlp.yvespeirsman.be/images/"
				
			
		>
	
	<meta name="twitter:title" content="Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model">
	<meta name="twitter:description" content="This is the website and blog of Yves Peirsman, Natural Language Processing Consultant.">
	<meta name="twitter:creator" content="@yvespeirsman">


<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model">
<meta property="og:description" content="This is the website and blog of Yves Peirsman, Natural Language Processing Consultant.">
<meta property="og:url" content="http://nlp.yvespeirsman.be/blog/text-retrieval-3/">
<meta property="og:site_name" content="Yves Peirsman">





<link rel="canonical" href="http://nlp.yvespeirsman.be/blog/text-retrieval-3/">
<link href="http://nlp.yvespeirsman.be/feed.xml" type="application/atom+xml" rel="alternate" title="Yves Peirsman Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Webfonts -->
<link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<!-- For all browsers -->
<link rel="stylesheet" href="http://nlp.yvespeirsman.be/assets/css/main.min.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://nlp.yvespeirsman.be/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://nlp.yvespeirsman.be/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://nlp.yvespeirsman.be/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://nlp.yvespeirsman.be/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://nlp.yvespeirsman.be/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://nlp.yvespeirsman.be/images/apple-touch-icon-144x144-precomposed.png">

<link rel="stylesheet" href="/css/yves.css">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body class="post">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
	</div> <!--/.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				<li><a href="http://nlp.yvespeirsman.be/" >Home</a></li>
		        
				<li><a href="http://nlp.yvespeirsman.be/blog/" >All Posts</a></li>
		        
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->




<div id="main" role="main">
  <div class="article-author-side">
    
	<a href="http://nlp.yvespeirsman.be"><img src="http://nlp.yvespeirsman.be/images/bio-photo.jpg" class="bio-photo" alt="Yves Peirsman bio photo"></a>

<h3><a href="http://nlp.yvespeirsman.be">Yves Peirsman</a></h3>
<p>Crazy about Natural Language Processing.</p>
<a href="http://twitter.com/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-twitter-square"></i> Twitter</a>


<a href="http://linkedin.com/in/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>










  </div>
  <article>
    <div class="headline-wrap">
      
        <h1><a href="http://nlp.yvespeirsman.be/blog/text-retrieval-3/" rel="bookmark" title="Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model">Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model</a></h1>
      
    </div><!--/ .headline-wrap -->
    <div class="article-wrap">
      <p class="first">This month I’m taking the online course <a href="https://www.coursera.org/course/textretrieval">Text Retrieval &amp; Search Engines</a> on Coursera, and I’m using this blog to write down the main takeaways every week. In this third week of the course, we again focused on two main topics: probabilistic models for information retrieval and methods for user feedback. In this blog post I share my notes on probabilistic models.</p>

<p>Probabilistic models for IR rank documents according to the probability that they are relevant to a query. There are several possible implementations, but in this course we focused on the so-called Query Likelihood Model. This approach makes the assumption that we can model $p(R=1|q,d)$, the probability that a document is relevant for a given query, as $p(q|d,R=1)$, the probability that the query is observed if a given document is relevant. In other words, if a user is interested in document $d$, how likely are they to enter query $q$? To answer this question, the Query Likelihood Model makes use of language models.</p>

<p>Language models are basically probability distributions over word sequences: they give us the probability of observing a certain word or word sequence in a text. Information Retrieval generally relies on <em>unigram</em> language models, which only have probabilities for single words. They assume that texts are created by drawing words at random, independently of one another. The presence of one word therefore does not tell us anything about the probability of observing another word. This assumption is clearly false, but it allows us to simplify our approach drastically. For example, we can now compute the probability of a text as the product of the probabilities of its words.</p>

<p>Now, to rank all documents for a query, we use each document in the collection to estimate a language model, and compute the probability of the query on the basis of the resulting word probabilities. The simplest way of building such a language model is with Maximum Likelihood Estimation, where we set the parameters in such a way that our observed data (the document) receives the highest possible probability. In practice, this means that we will use the relative frequencies of the words observed in the document as their probabilities: $$p(w|d) = \frac{c(w,d)}{|d|}$$</p>

<p>This Maximum Likelihood Estimation has one downside, however: because it assigns zero probability to words that were not observed in the document, any query with such an unseen word will receive a probability of zero. To solve this method, we need to <em>smooth</em> our language models: we take away some probability mass from the words that were observed in the document, and assign it to the unseen words. One of the most popular smoothing methods is Jelinek-Mercer Smoothing, which applies linear interpolation between the relative frequencies of the words in the document and their probability according to a language model on the basis of the full text collection: $$p(w|d)=(1-\lambda)\frac{c(w,d)}{|d|} + \lambda p(w|C)$$ Another effective method is Dirichlet Prior Smoothing. Here we add pseudo word counts to the observed text, based on the collection language model. As a result, the smoothing coefficient is dynamic, depending on the length of the document, and longer documents will receive less smoothing: $$p(w|d) = \frac{c(w,d) + \mu p(w|C)}{|d| + \mu} = \frac{|d|}{|d|+\mu}\frac{c(w,d)}{|d|} + \frac{\mu}{|d|+\mu} p(w|C)$$</p>

<p>One interesting result of these smoothing methods is that they lead to a ranking function that is very similar to the ranking methods we obtained with the vector space model. All the familiar heuristics, such as term frequency, inverse document frequency and document length normalization, are there, in one form or another. However, this time we obtained them in a very natural way: our new ranking functions followed quite automatically from thinking about information retrieval as a probabilistic problem.</p>

      <div class="addthis_sharing_toolbox"></div>
      <hr />
      <footer role="contentinfo">
        <div class="article-author-bottom">
          
	<a href="http://nlp.yvespeirsman.be"><img src="http://nlp.yvespeirsman.be/images/bio-photo.jpg" class="bio-photo" alt="Yves Peirsman bio photo"></a>

<h3><a href="http://nlp.yvespeirsman.be">Yves Peirsman</a></h3>
<p>Crazy about Natural Language Processing.</p>
<a href="http://twitter.com/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-twitter-square"></i> Twitter</a>


<a href="http://linkedin.com/in/yvespeirsman" class="author-social" target="_blank"><i class="fa fa-linkedin-square"></i> LinkedIn</a>










        </div>
        <p class="byline"><strong>Text Retrieval & Search Engines (Coursera): Week 3 Part 1: Query Likelihood Model</strong> was published on <time datetime="2015-04-13T05:00:00-04:00">April 13, 2015</time> by <a href="http://nlp.yvespeirsman.be/about" title="About Yves Peirsman">Yves Peirsman</a>.</p>
      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="http://nlp.yvespeirsman.be/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/generating-genre-fiction-with-deep-learning/" title="Generating Genre Fiction with Deep Learning">Generating Genre Fiction with Deep Learning</a></li>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/text-retrieval-6/" title="Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;2: Recommender Systems">Text Retrieval & Search Engines (Coursera): Week&nbsp;4 Part&nbsp;2: Recommender Systems</a></li>
    
      <li><a href="http://nlp.yvespeirsman.be/blog/visualizing-word-embeddings-with-tsne/" title="Visualizing Word Embeddings with t-SNE">Visualizing Word Embeddings with t-SNE</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  <footer>
    <span>&copy; 2015 Yves Peirsman. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->


<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://nlp.yvespeirsman.be/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://nlp.yvespeirsman.be/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53268217-1', 'auto');
  ga('send', 'pageview');
</script>



  <!-- Go to www.addthis.com/dashboard to customize your tools -->
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-53fb5daa449762bb"></script>
  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yvespeirsman'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



	        

</body>
</html>
